{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Watson_with_word2vec_and_BERT.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM+GneoxTvT+/l5PlcjjVRf"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"s7nCoW5_kBAr","executionInfo":{"status":"ok","timestamp":1603647343426,"user_tz":-420,"elapsed":45793,"user":{"displayName":"YUSRAN HADI 05111740000105","photoUrl":"","userId":"01927490012154636858"}},"outputId":"f767ae9b-ae26-4de7-8be2-b51622660122","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","!pip install -U sentence-transformers\n","!pip install gensim\n","from gensim.test.utils import common_texts, get_tmpfile\n","from gensim.models import Word2Vec \n","from google.colab import drive\n","import json\n","!pip install --upgrade ibm-watson\n","from ibm_watson import AssistantV1\n","from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n","import itertools\n","import nltk\n","nltk.download('punkt')\n","import re\n","import math\n","import glob\n","import os\n","!pip install python-docx\n","from gensim.models import Doc2Vec\n","import docx\n","import time\n","import gc\n","import torch\n","from sentence_transformers import SentenceTransformer, util\n","\n","drive.mount('/content/drive')\n","iamAutentikator = 'Jljl7cVGjh5Jmm9E8OHYI1iu7xmNSoGOyUaZqtBwewUG'\n","workspaceID = 'e13262d3-e6e1-4ad5-b460-9561ffefbdb1'\n","assistantURL = 'https://api.us-south.assistant.watson.cloud.ibm.com'\n","\n","authenticator = IAMAuthenticator(iamAutentikator)\n","assistant = AssistantV1(\n","    version='2020-04-01',\n","    authenticator = authenticator\n",")\n","\n","assistant.set_service_url(assistantURL)\n","\n","listDatas = []\n","\n","# model = FastText.load('idwiki_word2vec_200.model')\n","# model = KeyedVectors.load_word2vec_format('cc.id.300.vec')\n","\n","\n","def createIntent(question, ans, examp):\n","  \n","  intent_in = str(question).replace(\" \", \"\")\n","  more_examp = \" \".join(ans)\n","  response=assistant.create_intent(\n","      workspace_id=workspaceID,\n","      intent=intent_in,\n","      examples=[\n","          {'text': examp[0]},\n","          {'text': examp[1]},\n","          {'text': examp[2]},\n","          {'text': examp[3]},\n","          {'text': examp[4]},\n","          {'text': examp[5]},\n","          {'text': examp[6]},\n","          {'text': examp[7]},\n","          {'text': examp[8]},\n","          {'text': examp[9]},\n","          {'text': question},\n","         # {'text': more_examp}\n","          \n","      ]\n","  ).get_result()\n","\n","  del examp\n","  del intent_in\n","  del more_examp\n","  del response\n","  gc.collect()\n","\n","def createDialog(question, ans):\n","    intent_in = str(question).replace(\" \", \"\")\n","    con = \"#\" + intent_in\n","    answer = list2string(ans)\n","    response=assistant.create_dialog_node(\n","        workspace_id=workspaceID,\n","        dialog_node=question,\n","        conditions=con,\n","        output={\n","            'generic': [\n","                {\n","                    'response_type': 'text',\n","                    'values': [\n","                        {\n","                            'text': answer\n","                        }\n","                    ]\n","                }\n","            ]\n","        }\n","    ).get_result()\n","\n","    del con\n","    del answer\n","    del intent_in\n","    del response\n","    gc.collect()\n","\n","\n","def updateIntent(question, ans, examp):\n","    # examp = makeExamp(question)\n","    intent_in = str(question).replace(\" \", \"\")\n","    more_examp = \" \".join(ans)\n","    # print(more_examp)\n","    response=assistant.update_intent(\n","        workspace_id=workspaceID,\n","        intent=intent_in,\n","        new_examples=[\n","            {'text': examp[0]},\n","            {'text': examp[1]},\n","            {'text': examp[2]},\n","            {'text': examp[3]},\n","            {'text': examp[4]},\n","            {'text': examp[5]},\n","            {'text': examp[6]},\n","            {'text': examp[7]},\n","            {'text': examp[8]},\n","            {'text': examp[9]},\n","            {'text': question},\n","           # {'text': more_examp}\n","        ]   \n","    ).get_result\n","\n","    del examp\n","    del intent_in\n","    del more_examp\n","    del response\n","    # gc.collect()\n","\n","def updateDialog(question, ans):\n","    intent_in = str(question).replace(\" \", \"\")\n","    con = '#' + intent_in\n","    answer = list2string(ans)\n","    response=assistant.update_dialog_node(\n","        workspace_id=workspaceID,\n","        dialog_node=question,\n","        conditions=con,\n","        new_output={\n","            'generic': [\n","                {\n","                    'response_type': 'text',\n","                    'values': [\n","                        {\n","                            'text': answer\n","                        }\n","                    ]\n","                }\n","            ]\n","        }\n","    ).get_result()\n","\n","    del con\n","    del answer\n","    del intent_in\n","    del response\n","    # gc.collect()\n","    # print(json.dumps(response, indent=2))\n","\n","def list2string(s):\n","    str1 = '\\n'\n","\n","    return str1.join(s)\n","\n","def getdoc():\n","  path = '/content/drive/My Drive/Colab Notebooks/DOKUMEN/'\n","    # array     \n","    \n","  for filename in glob.glob(os.path.join(path, '*.docx')):\n","    files = docx.Document(filename)\n","    ans = []\n","    # for para in files.paragraphs:\n","    #     teks.append(para.text)\n","    \n","    question = files.paragraphs[0].text\n","    question = re.sub('[^A-Za-z0-9]+',' ', question)\n","\n","    for i in range(1, len(files.paragraphs)):\n","        para = files.paragraphs[i].text\n","        ans.append(para)\n","\n","    examp = makeExamp(question)\n","    # print(ans)\n","    # print(\" \".join(ans))\n","    try:\n","        # question = str(question).replace(\" \", \"\")\n","        # print(question)\n","        \n","        createIntent(question, ans, examp)\n","        \n","    except:\n","        # question = str(question).replace(\" \", \"\")\n","        \n","        updateIntent(question, ans, examp)\n","    \n","    try:\n","        \n","        createDialog(question, ans)\n","        \n","    except:\n","        \n","        updateDialog(question, ans)\n","    \n","    \n","    gc.collect()\n","    \n","\n","def makeExamp(kalimat):\n","  kalimat = kalimat.lower()\n","  words = kalimat.split()\n","  sim_words = []\n","\n","  kal_vec = model_bert.encode(kalimat, convert_to_tensor=True)\n","\n","  for word in words:\n","    temp = []\n","    try:\n","      sim_word = model.wv.most_similar(positive=word, topn=2)\n","      for each in sim_word:\n","        temp.append(each[0])\n","      \n","    except:\n","      temp.append(word)\n","    sim_words.append(temp)\n","    \n","  \n","\n","  sentence = list(itertools.product(*sim_words))\n","  del sim_words\n","  del words\n","  \n","\n","  corp = []  \n","  #   sentence.append(sen)\n","  for each in sentence:\n","    temp = ' '.join(each)\n","    corp.append(temp)\n","    \n","  \n","  del sentence\n","\n","  # examp = []\n","  #vecs = []\n","  #important\n","\n","  # kal_vec = doc_model.wv.get_vector(kalimat)\n","\n","  # for each_sentence in corp:\n","    \n","  #   vecs.append(doc_model.wv.get_vector(each_sentence))\n","  vecs = model_bert.encode(corp, convert_to_tensor=True)\n","\n","  cos_sim = util.pytorch_cos_sim(kal_vec, vecs)[0]\n","    \n","  # cos_sim = model.wv.cosine_similarities(kal_vec, vecs)\n","  \n","    \n","\n","  # k = 0\n","  # for i in corp:\n","  #   temp = (cos_sim[k], i)\n","  #   k = k+1\n","  #   examp.append(temp)\n","\n","  # p_sort = sorted(examp, reverse=True)\n","\n","  # res = p_sort[:10]\n","  # res = corp[:10]\n","  res = []\n","  cos_sim = cos_sim.cpu()\n","  top_res = torch.topk(cos_sim, k=10)\n","\n","  for score, idx in zip(top_res[0], top_res[1]):\n","    res.append(corp[idx])\n","    print(corp[idx], \"(Score: %.4f)\" % (score))\n","\n","  # del examp\n","  del corp\n","  # del p_sort\n","  del kal_vec\n","  del cos_sim\n","  # del k\n","  del vecs\n","  \n","  gc.collect()\n","  \n","\n","  return res\n","\n","# name = input()\n","model = Word2Vec.load('/content/drive/My Drive/Colab Notebooks/Model/idwiki_word2vec_200_new_lower.model')\n","# # fast_model = FastText.load_facebook_vectors('/content/drive/My Drive/Colab Notebooks/Model/cc.id.300.vec')\n","# doc_model = Doc2Vec.load('/content/drive/My Drive/Colab Notebooks/Model/idwiki_word2vec_200_new_lower.model')\n","model_bert = SentenceTransformer('distiluse-base-multilingual-cased')\n","getdoc()\n","# makeExamp('apakah sudah ada obat untuk covid19')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: sentence-transformers in /usr/local/lib/python3.6/dist-packages (0.3.8)\n","Requirement already satisfied, skipping upgrade: transformers<3.4.0,>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.3.1)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n","Requirement already satisfied, skipping upgrade: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.6.0+cu101)\n","Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n","Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n","Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (0.7)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (3.0.12)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (2.23.0)\n","Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (0.0.43)\n","Requirement already satisfied, skipping upgrade: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (0.1.94)\n","Requirement already satisfied, skipping upgrade: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (0.8.1rc2)\n","Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (20.4)\n","Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers) (0.16.0)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.16.0)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (2020.6.20)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (3.0.4)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.4.0,>=3.1.0->sentence-transformers) (7.1.2)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.4.0,>=3.1.0->sentence-transformers) (2.4.7)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.2.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n","Requirement already up-to-date: ibm-watson in /usr/local/lib/python3.6/dist-packages (4.7.1)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from ibm-watson) (2.8.1)\n","Requirement already satisfied, skipping upgrade: requests<3.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from ibm-watson) (2.23.0)\n","Requirement already satisfied, skipping upgrade: ibm-cloud-sdk-core==1.7.3 in /usr/local/lib/python3.6/dist-packages (from ibm-watson) (1.7.3)\n","Requirement already satisfied, skipping upgrade: websocket-client==0.48.0 in /usr/local/lib/python3.6/dist-packages (from ibm-watson) (0.48.0)\n","Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.3->ibm-watson) (1.15.0)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.0->ibm-watson) (1.24.3)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.0->ibm-watson) (2.10)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.0->ibm-watson) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.0->ibm-watson) (2020.6.20)\n","Requirement already satisfied, skipping upgrade: PyJWT>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from ibm-cloud-sdk-core==1.7.3->ibm-watson) (1.7.1)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","Requirement already satisfied: python-docx in /usr/local/lib/python3.6/dist-packages (0.8.10)\n","Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from python-docx) (4.2.6)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n","/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"stream","text":["metode melindunginya dirinya apabila tak menyadari siapakah tersebut tertular covid 19 (Score: 0.8495)\n","metode melindunginya lugosi apabila tak menyadari siapakah tersebut tertular covid 19 (Score: 0.8472)\n","metode melindunginya dirinya bila tak menyadari siapakah tersebut tertular covid 19 (Score: 0.8364)\n","metode melindunginya dirinya apabila tak menyadari siapakah tersebut disuntik covid 19 (Score: 0.8359)\n","metode melindunginya lugosi apabila belum menyadari siapakah tersebut tertular covid 19 (Score: 0.8346)\n","metode melindunginya dirinya apabila belum menyadari siapakah tersebut tertular covid 19 (Score: 0.8344)\n","metode melindunginya dirinya apabila tak menyadari apa tersebut tertular covid 19 (Score: 0.8309)\n","caranya melindunginya dirinya apabila tak menyadari siapakah tersebut tertular covid 19 (Score: 0.8309)\n","metode melindunginya lugosi apabila tak menyadari siapakah tersebut disuntik covid 19 (Score: 0.8306)\n","metode melindunginya dirinya bila belum menyadari siapakah tersebut tertular covid 19 (Score: 0.8295)\n"],"name":"stdout"}]}]}